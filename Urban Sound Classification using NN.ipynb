{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import pickle\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import specgram\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 10\n",
    "plt.rcParams['ytick.labelsize'] = 10\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rootDir = '/home/jan/projects/UrbanSound8K/audio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sound_files(file_paths):\n",
    "    raw_sounds = []\n",
    "    for fp in file_paths:\n",
    "        X,sr = librosa.load(os.path.join(rootDir,'fold1',fp))\n",
    "        raw_sounds.append(X)\n",
    "    return raw_sounds\n",
    "\n",
    "def plot_waves(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(16,40))\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        librosa.display.waveplot(np.array(f),sr=22050)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 1: Waveplot',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(16,40))\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        specgram(np.array(f), Fs=22050)\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 2: Spectrogram',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()\n",
    "\n",
    "def plot_log_power_specgram(sound_names,raw_sounds):\n",
    "    i = 1\n",
    "    fig = plt.figure(figsize=(16,40))\n",
    "    for n,f in zip(sound_names,raw_sounds):\n",
    "        plt.subplot(10,1,i)\n",
    "        D = librosa.logamplitude(np.abs(librosa.stft(f))**2, ref_power=np.max)\n",
    "        librosa.display.specshow(D,x_axis='time' ,y_axis='log')\n",
    "        plt.title(n.title())\n",
    "        i += 1\n",
    "    plt.suptitle('Figure 3: Log power spectrogram',x=0.5, y=0.915,fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sound_file_paths = [\"57320-0-0-7.wav\",\"24074-1-0-3.wav\",\"15564-2-0-1.wav\",\"31323-3-0-1.wav\",\"46669-4-0-35.wav\",\n",
    "                   \"89948-5-0-0.wav\",\"40722-8-0-4.wav\",\"103074-7-3-2.wav\",\"106905-8-0-0.wav\",\"108041-9-0-4.wav\"]\n",
    "sound_names = [\"air conditioner\",\"car horn\",\"children playing\",\"dog bark\",\"drilling\",\"engine idling\",\n",
    "               \"gun shot\",\"jackhammer\",\"siren\",\"street music\"]\n",
    "\n",
    "raw_sounds = load_sound_files(sound_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot_waves(sound_names,raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot_specgram(sound_names,raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#plot_log_power_specgram(sound_names,raw_sounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_feature(file_name):\n",
    "    X, sample_rate = librosa.load(file_name)\n",
    "    stft = np.abs(librosa.stft(X))\n",
    "    mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T,axis=0)\n",
    "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
    "    mel = np.mean(librosa.feature.melspectrogram(X, sr=sample_rate).T,axis=0)\n",
    "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
    "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(X), sr=sample_rate).T,axis=0)\n",
    "    return mfccs,chroma,mel,contrast,tonnetz\n",
    "\n",
    "def parse_audio_files(parent_dir,sub_dirs,file_ext='*.wav'):\n",
    "    features, labels = np.empty((0,193)), np.empty(0)\n",
    "    for label, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            print(fn)\n",
    "            if os.path.getsize(fn) > 20000:\n",
    "                mfccs, chroma, mel, contrast,tonnetz = extract_feature(fn)\n",
    "                ext_features = np.hstack([mfccs,chroma,mel,contrast,tonnetz])\n",
    "                features = np.vstack([features,ext_features])\n",
    "                labels = np.append(labels, os.path.basename(fn).split('-')[1])\n",
    "    return np.array(features), np.array(labels, dtype = np.int)\n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract_feature(rootDir+'/fold5/6508-9-1-0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_dirs = ['fold1','fold2','fold3']\n",
    "features, labels = parse_audio_files(rootDir,sub_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickleFile = open('features_NN_123.p', 'wb')\n",
    "#pickle.dump(features, pickleFile, pickle.HIGHEST_PROTOCOL)\n",
    "#pickle.dump(labels, pickleFile, pickle.HIGHEST_PROTOCOL)\n",
    "#pickleFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickleFile = open('features_NN_123.p', 'rb')\n",
    "features = pickle.load(pickleFile)\n",
    "labels = pickle.load(pickleFile)\n",
    "pickleFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = one_hot_encode(labels)\n",
    "\n",
    "train_test_split = np.random.rand(len(features)) < 0.70\n",
    "train_x = features[train_test_split]\n",
    "train_y = labels[train_test_split]\n",
    "test_x = features[~train_test_split]\n",
    "test_y = labels[~train_test_split]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Neural Network with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 5000\n",
    "n_dim = features.shape[1]\n",
    "n_classes = 10\n",
    "n_hidden_units_one = 280 \n",
    "n_hidden_units_two = 300\n",
    "sd = 1 / np.sqrt(n_dim)\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,n_dim])\n",
    "Y = tf.placeholder(tf.float32,[None,n_classes])\n",
    "\n",
    "W_1 = tf.Variable(tf.random_normal([n_dim,n_hidden_units_one], mean = 0, stddev=sd))\n",
    "b_1 = tf.Variable(tf.random_normal([n_hidden_units_one], mean = 0, stddev=sd))\n",
    "h_1 = tf.nn.tanh(tf.matmul(X,W_1) + b_1)\n",
    "\n",
    "\n",
    "W_2 = tf.Variable(tf.random_normal([n_hidden_units_one,n_hidden_units_two], mean = 0, stddev=sd))\n",
    "b_2 = tf.Variable(tf.random_normal([n_hidden_units_two], mean = 0, stddev=sd))\n",
    "h_2 = tf.nn.sigmoid(tf.matmul(h_1,W_2) + b_2)\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden_units_two,n_classes], mean = 0, stddev=sd))\n",
    "b = tf.Variable(tf.random_normal([n_classes], mean = 0, stddev=sd))\n",
    "y_ = tf.nn.softmax(tf.matmul(h_2,W) + b)\n",
    "\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_function = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y_), reduction_indices=[1])) \n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(training_epochs):           \n",
    "    _,cost = sess.run([optimizer,cost_function],feed_dict={X:train_x,Y:train_y})\n",
    "    cost_history = np.append(cost_history,cost)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(epoch,cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cost_history[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sess.run(tf.argmax(y_,1),feed_dict={X: test_x})\n",
    "y_true = sess.run(tf.argmax(test_y,1))\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "print(np.sum(y_pred == y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
